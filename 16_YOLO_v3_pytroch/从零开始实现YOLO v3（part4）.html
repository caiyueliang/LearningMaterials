<!DOCTYPE html>
<!-- saved from url=(0037)https://zhuanlan.zhihu.com/p/36998818 -->
<html lang="zh" data-hairline="true" data-theme="light" data-focus-method="pointer"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>从零开始实现YOLO v3（part4）</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-react-helmet="true" property="description" content="（仅供学术交流，未经同意，请勿转载）（本文翻译自：Tutorial on implementing YOLO v3 from scratch in PyTorch）（这篇文章的原作者，原作者，原作者（重要的话说3遍）真的写得很好很用心，去github上给他打个…"><meta data-react-helmet="true" property="og:title" content="从零开始实现YOLO v3（part4）"><meta data-react-helmet="true" property="og:url" content="http://zhuanlan.zhihu.com/p/36998818"><meta data-react-helmet="true" property="og:description" content="（仅供学术交流，未经同意，请勿转载）（本文翻译自：Tutorial on implementing YOLO v3 from scratch in PyTorch）（这篇文章的原作者，原作者，原作者（重要的话说3遍）真的写得很好很用心，去github上给他打个…"><meta data-react-helmet="true" property="og:image" content="https://pic3.zhimg.com/v2-986adea1a9f8e7373786d26eb38dbd1b_r.jpg"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"><link rel="dns-prefetch" href="https://static.zhimg.com/"><link rel="dns-prefetch" href="https://pic1.zhimg.com/"><link rel="dns-prefetch" href="https://pic2.zhimg.com/"><link rel="dns-prefetch" href="https://pic3.zhimg.com/"><link rel="dns-prefetch" href="https://pic4.zhimg.com/"><link href="./从零开始实现YOLO v3（part4）_files/column.app.9fe115b38c7d2aff7e67.css" rel="stylesheet"><script type="text/javascript" charset="utf-8" async="" src="./从零开始实现YOLO v3（part4）_files/column.modals.2d41e7c3d8e264d046f5.js.下载"></script><script type="text/javascript" charset="utf-8" async="" src="./从零开始实现YOLO v3（part4）_files/column.richinput.f9f8c1d5d950d791a566.js.下载"></script></head><body class=""><div id="root"><div class="App" data-reactroot=""><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;yue-liang-he-xiao&quot;}" data-zop="{&quot;authorName&quot;:&quot;深度智能&quot;,&quot;itemId&quot;:36998818,&quot;title&quot;:&quot;从零开始实现YOLO v3（part4）&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;36998818&quot;}}}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader is-fixed" style="width: 1519.2px; top: 0px; left: 0px;"><div class="ColumnPageHeader-content"><a href="https://www.zhihu.com/" aria-label="知乎"><svg viewBox="0 0 200 91" class="Icon ZhihuLogo Icon--logo" style="height:30px;width:64px" width="64" height="30" aria-hidden="true"><title></title><g><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></g></svg></a><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button><div class="Popover"><button title="更多" type="button" id="Popover-96272-88257-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96272-88257-content" class="Button ColumnPageHeader-MenuToggler Button--plain"><svg class="Zi Zi--Dots" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></button></div></div></div></div><div class="Sticky--holder" style="position: relative; top: 0px; right: 0px; bottom: 0px; left: 0px; display: block; float: none; margin: 0px; height: 52px;"></div></div></div><img class="TitleImage" src="./从零开始实现YOLO v3（part4）_files/v2-986adea1a9f8e7373786d26eb38dbd1b_1200x500.jpg" alt="从零开始实现YOLO v3（part4）"><article class="Post-Main Post-NormalMain"><header class="Post-Header"><h1 class="Post-Title">从零开始实现YOLO v3（part4）</h1><div class="Post-Author"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="深度智能"><meta itemprop="image" content="https://pic3.zhimg.com/v2-28e3b30287fee9592c446551a23a6ec7_is.jpg"><meta itemprop="url" content="https://www.zhihu.com/people/shen-du-zhi-neng"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover-96275-58802-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96275-58802-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shen-du-zhi-neng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="./从零开始实现YOLO v3（part4）_files/v2-28e3b30287fee9592c446551a23a6ec7_xs.jpg" srcset="https://pic3.zhimg.com/v2-28e3b30287fee9592c446551a23a6ec7_l.jpg 2x" alt="深度智能"></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover-96275-4600-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96275-4600-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shen-du-zhi-neng">深度智能</a></div></div></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="RichText ztext AuthorInfo-badgeText">深度学习经典与最新论文解析，论文实现等</div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--grey">已关注</button></div><div><span class="Voters"><button type="button" class="Button Button--plain">2 人<!-- -->赞了该文章</button></span></div></header><div><div class="RichText ztext Post-RichText"><p><i>（仅供学术交流，未经同意，请勿转载）</i></p><p><i>（本文翻译自：<a href="https://link.zhihu.com/?target=https%3A//blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-4/" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Tutorial on implementing YOLO v3 from scratch in PyTorch</a>）</i></p><p><i>（这篇文章的原作者，原作者，原作者（重要的话说3遍）真的写得很好很用心，去</i><a href="https://link.zhihu.com/?target=https%3A//github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">github</a><i>上给他打个星星✨吧）</i></p><p><br></p><p>这是从零开始实现YOLO v3检测器的教程的第4部分。在上一部分，我们实现了网络的前向传播。在这部分中，我们根据目标置信度和阀值过滤检测结果，并使用非最大值抑制得到最终的检测结果。</p><p><br></p><p>本教程的代码旨在运行在Python 3.5和PyTorch 0.4上。它可以在这个<a href="https://link.zhihu.com/?target=https%3A//github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Github</a>中找到。</p><p><br></p><p>本教程分为5个部分：</p><p><br></p><p>第1部分：<a href="https://zhuanlan.zhihu.com/p/36899263" class="internal" data-za-detail-view-id="1043">了解YOLO如何工作</a></p><p>第2部分：<a href="https://zhuanlan.zhihu.com/p/36920744" class="internal" data-za-detail-view-id="1043">创建网络结构的层</a></p><p>第3部分：<a href="https://zhuanlan.zhihu.com/p/36984201" class="internal" data-za-detail-view-id="1043">实现网络的前向传播</a></p><p>第4部分（本文）：<a href="https://zhuanlan.zhihu.com/p/36998818" class="internal" data-za-detail-view-id="1043">目标分数阈值和非最大值抑制</a></p><p>第5部分：<a href="https://zhuanlan.zhihu.com/p/37007960" class="internal" data-za-detail-view-id="1043">设计输入和输出流程</a></p><p><br></p><p><br></p><h2><b>预备知识</b></h2><ul><li>本教程的第1-3部分。</li><li>PyTorch的基本知识，包括如何使用<i>nn.Module，nn.Sequential和torch.nn.parameter</i>类创建自定义体系结构。</li><li>NumPy的基本知识</li></ul><p>如果你有任何不懂的地方，可以通过本文下面的链接查看相关知识。</p><p><br></p><p>在前面的部分中，我们已经建立了一个模型，对于给定的输入图像，输出多个目标检测结果。准确地说，我们的输出是B×10647×85形状的张量。B是一个批量中图像的数量，10647是每个图像预测的边界框的数量，85是边界框属性的数量。</p><p><br></p><p>但是，如第1部分所述，我们必须将输出结果根据目标分数阈值和非最大值抑制来获得<i>true</i>检测结果（我将在本文其余部分中使用该名称）。为此，我们将在<i>util.py</i>文件中创建一个名为<i>write_results</i>的函数。</p><div class="highlight"><pre><code class="language-text"><span></span>def write_results(prediction, confidence, num_classes, nms_conf = 0.4):
</code></pre></div><p><br></p><p>这些函数将输入预测，置信度（目标分数阈值），num_classes（在我们的例子中为80）和nms_conf（NMS IoU阈值）作为输入。</p><h2><b>目标置信度阈值</b></h2><p>我们的预测张量包含B x 10647个边界框的信息。对于每个具有低于阈值的目标分数的边界框，我们将它的每个属性（边界框的整个行）的值设置为零。</p><div class="highlight"><pre><code class="language-text"><span></span>    conf_mask = (prediction[:,:,4] &gt; confidence).float().unsqueeze(2)
    prediction = prediction*conf_mask
</code></pre></div><p><br></p><h2><b>执行非最大值抑制</b></h2><p>注意：我假设你已经理解什么是IoU（Intersection over Union）和非最大值抑制。如果你还不清楚，请参阅本文末尾的链接）。</p><p><br></p><p>我们现在具有的边界框属性由中心坐标以及边界框的高度和宽度描述。但是，使用每个框的一对角点的坐标来计算两个框的IoU更容易。因此，我们将框的（中心x，中心y，高度，宽度）属性转换为（左上角x，左上角y，右下角x，右下角y）。</p><div class="highlight"><pre><code class="language-text"><span></span>    box_corner = prediction.new(prediction.shape)
    box_corner[:,:,0] = (prediction[:,:,0] - prediction[:,:,2]/2)
    box_corner[:,:,1] = (prediction[:,:,1] - prediction[:,:,3]/2)
    box_corner[:,:,2] = (prediction[:,:,0] + prediction[:,:,2]/2) 
    box_corner[:,:,3] = (prediction[:,:,1] + prediction[:,:,3]/2)
    prediction[:,:,:4] = box_corner[:,:,:4]
</code></pre></div><p><br></p><p>每幅图像中的<i>true</i>检测结果的数量可能不同。例如，批量大小为3，图像1,2和3分别具有5个，2个和4个<i>true</i>检测结果。因此，一次只能对一张图像进行置信度阈值和NMS。这意味着，我们不能向量化所涉及的操作，并且必须在<i>prediction</i>的第一维（包含批量中的图像索引）上进行循环。</p><div class="highlight"><pre><code class="language-text"><span></span>    batch_size = prediction.size(0)

    write = False

    for ind in range(batch_size):
        image_pred = prediction[ind]          #image Tensor
           #confidence threshholding 
           #NMS
   
</code></pre></div><p><br></p><p>如前所述，<i>write</i>标志用于指示我们尚未初始化<i>output</i>，我们将使用张量来保存整个批量的<i>true</i>检测结果。</p><p><br></p><p>进入循环后，让我们进一步作出解释。注意每个边界框行有85个属性，其中80个是类别分数。此时，我们只关心具有最大值的类别分数。因此，我们从每一行中删除80个类别的分数，并添加具有最大值的类别的索引，以及该类别的类别分数。</p><div class="highlight"><pre><code class="language-text"><span></span>        max_conf, max_conf_score = torch.max(image_pred[:,5:5+ num_classes], 1)
        max_conf = max_conf.float().unsqueeze(1)
        max_conf_score = max_conf_score.float().unsqueeze(1)
        seq = (image_pred[:,:5], max_conf, max_conf_score)
        image_pred = torch.cat(seq, 1)
</code></pre></div><p><br></p><p>还记得我们已经将具有小于阈值的目标置信度的边界框行设置为零吗？现在让我们清除它们。</p><div class="highlight"><pre><code class="language-text"><span></span>non_zero_ind =  (torch.nonzero(image_pred[:,4]))
try:
    image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(-1,7)
    except:
       continue
        
        #For PyTorch 0.4 compatibility
        #Since the above code with not raise exception for no detection 
        #as scalars are supported in PyTorch 0.4
    if image_pred_.shape[0] == 0:
        continue 
</code></pre></div><p><br></p><p>try-except块用于处理没有检测到的情况。在这种情况下，我们使用continue来跳过该图像的循环体的其余部分。</p><p><br></p><p>现在，我们来看一个图像中检测到的类。</p><div class="highlight"><pre><code class="language-text"><span></span>        #Get the various classes detected in the image
        img_classes = unique(image_pred_[:,-1]) # -1 index holds the class index
</code></pre></div><p><br></p><p>由于同一个类可以有多个true检测结果，我们使用一个称为<i>unique</i>的函数来获取任何给定图像中存在的类。</p><div class="highlight"><pre><code class="language-text"><span></span>def unique(tensor):
    tensor_np = tensor.cpu().numpy()
    unique_np = np.unique(tensor_np)
    unique_tensor = torch.from_numpy(unique_np)
    
    tensor_res = tensor.new(unique_tensor.shape)
    tensor_res.copy_(unique_tensor)
    return tensor_res
</code></pre></div><p><br></p><p>然后，我们按类别进行NMS。</p><div class="highlight"><pre><code class="language-text"><span></span>    for cls in img_classes:
        #perform NMS
</code></pre></div><p><br></p><p>一旦我们进入循环，我们所做的第一件事就是提取特定类的检测结果（用变量cls表示）。</p><p><br></p><p>以下代码在原代码文件中有三格缩进，但由于该页面上的空间有限，因此我没有在此缩进。</p><div class="highlight"><pre><code class="language-text"><span></span>#get the detections with one particular class
cls_mask = image_pred_*(image_pred_[:,-1] == cls).float().unsqueeze(1)
class_mask_ind = torch.nonzero(cls_mask[:,-2]).squeeze()
image_pred_class = image_pred_[class_mask_ind].view(-1,7)

#sort the detections such that the entry with the maximum objectness
s#confidence is at the top
conf_sort_index = torch.sort(image_pred_class[:,4], descending = True )[1]
image_pred_class = image_pred_class[conf_sort_index]
idx = image_pred_class.size(0)   #Number of detections
</code></pre></div><p><br></p><p>现在，我们执行NMS。</p><div class="highlight"><pre><code class="language-text"><span></span>for i in range(idx):
    #Get the IOUs of all boxes that come after the one we are looking at 
    #in the loop
    try:
        ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])
    except ValueError:
        break

    except IndexError:
        break

    #Zero out all the detections that have IoU &gt; treshhold
    iou_mask = (ious &lt; nms_conf).float().unsqueeze(1)
    image_pred_class[i+1:] *= iou_mask       

    #Remove the non-zero entries
    non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()
    image_pred_class = image_pred_class[non_zero_ind].view(-1,7)
</code></pre></div><p><br></p><p>在这里，我们使用一个函数bbox_iou，它的第一个参数是由循环中变量i索引的边界框行。</p><p><br></p><p>bbox_iou的第二个参数是包含多行边界框的张量。函数bbox_iou的输出是一个张量，它包含第一个参数所表示的边界框与第二个参数中的每个边界框的IoU。</p><figure><noscript><img src="https://pic1.zhimg.com/v2-4375aa03da0093158ef1dc3436ae7fa9_b.jpg" data-caption="" data-size="normal" data-rawwidth="2046" data-rawheight="1056" class="origin_image zh-lightbox-thumb" width="2046" data-original="https://pic1.zhimg.com/v2-4375aa03da0093158ef1dc3436ae7fa9_r.jpg"></noscript><img src="./从零开始实现YOLO v3（part4）_files/v2-4375aa03da0093158ef1dc3436ae7fa9_hd.jpg" data-caption="" data-size="normal" data-rawwidth="2046" data-rawheight="1056" class="origin_image zh-lightbox-thumb lazy" width="2046" data-original="https://pic1.zhimg.com/v2-4375aa03da0093158ef1dc3436ae7fa9_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4375aa03da0093158ef1dc3436ae7fa9_b.jpg"></figure><p><br></p><p>如果我们有两个相同类别的边界框的IoU大于阀值，则具有较低类别置信度的边界框被去除。我们已经把边界框按照其置信度从高到低的顺序排列好。</p><p><br></p><p>在循环体中，以下行给出了索引为i的框与所有索引都高于i的边界框的IoU。</p><div class="highlight"><pre><code class="language-text"><span></span>ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])
</code></pre></div><p><br></p><p>每次迭代，任何具有索引大于i的的边界框，若其IoU大于阈值nms_thresh（具有由i索引的框），则该边界框将被去除。</p><div class="highlight"><pre><code class="language-text"><span></span>#Zero out all the detections that have IoU &gt; treshhold
iou_mask = (ious &lt; nms_conf).float().unsqueeze(1)
image_pred_class[i+1:] *= iou_mask       

#Remove the non-zero entries
non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()
image_pred_class = image_pred_class[non_zero_ind]   
</code></pre></div><p><br></p><p>另外请注意，我们已经将计算IoU的代码行放在try-catch块中。这是因为循环被设计为运行idx迭代（image_pred_class中的行数）。但是，当我们继续循环时，可能会从image_pred_class中删除多个边界框。这意味着，即使从image_pred_class中删除了一个值，我们也不能进行idx迭代。因此，我们可能会索引超出范围的值（IndexError），或者slice_pred_class [i + 1：]可能会返回一个空张量，而赋予空张量的值会触发ValueError。在那个时候，我们可以确定NMS不会删除更多的边界框，并且跳出循环。</p><p><br></p><h2><b>计算IoU</b></h2><p>这是bbox_iou函数。</p><div class="highlight"><pre><code class="language-text"><span></span>def bbox_iou(box1, box2):
    """
    Returns the IoU of two bounding boxes 
    
    
    """
    #Get the coordinates of bounding boxes
    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]
    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]
    
    #get the corrdinates of the intersection rectangle
    inter_rect_x1 =  torch.max(b1_x1, b2_x1)
    inter_rect_y1 =  torch.max(b1_y1, b2_y1)
    inter_rect_x2 =  torch.min(b1_x2, b2_x2)
    inter_rect_y2 =  torch.min(b1_y2, b2_y2)
    
    #Intersection area
    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)
 
    #Union Area
    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)
    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)
    
    iou = inter_area / (b1_area + b2_area - inter_area)
    
    return iou

def bbox_iou(box1, box2):
    """
    Returns the IoU of two bounding boxes 
    
    
    """
    #Get the coordinates of bounding boxes
    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]
    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]
    
    #get the corrdinates of the intersection rectangle
    inter_rect_x1 =  torch.max(b1_x1, b2_x1)
    inter_rect_y1 =  torch.max(b1_y1, b2_y1)
    inter_rect_x2 =  torch.min(b1_x2, b2_x2)
    inter_rect_y2 =  torch.min(b1_y2, b2_y2)
    
    #Intersection area
    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)
 
    #Union Area
    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)
    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)
    
    iou = inter_area / (b1_area + b2_area - inter_area)
    
    return iou
</code></pre></div><p><br></p><h2><b>写入预测结果</b></h2><p>函数<i>write_results</i>输出形状为D x 8的张量。这里D是所有图像的<i>true</i>检测，每个检测由一行表示。每个检测有8个属性，即检测的图像在所属批次中的索引，4个角坐标，目标分数，最大置信度类别的分数以及该类别的索引。</p><p><br></p><p>和以前一样，除非我们有一个检测分配给它，否则我们不会初始化输出张量。一旦它被初始化，我们把后续的检测与它连接。我们使用<i>write</i>标志来指示张量是否已经初始化。在遍历类的循环结束时，我们将检测结果添加到张量<i>output</i>中。</p><div class="highlight"><pre><code class="language-text"><span></span>            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)      
            #Repeat the batch_id for as many detections of the class cls in the image
            seq = batch_ind, image_pred_class

            if not write:
                output = torch.cat(seq,1)
                write = True
            else:
                out = torch.cat(seq,1)
                output = torch.cat((output,out))
</code></pre></div><p><br></p><p>在函数结束时，我们检查输出是否已经被初始化。如果它没有意味着在该批次的任何图像都没有检测到任何目标。在这种情况下，我们返回0。</p><div class="highlight"><pre><code class="language-text"><span></span>    try:
        return output
    except:
        return 0
</code></pre></div><p><br></p><p>这部分到此结束。在这篇文章的最后，我们终于有了一个预测张量，它将每个预测列为行。现在唯一剩下的就是创建一个输入流程，从磁盘读取图像，计算预测结果，在图像上绘制边界框，然后显示/写入这些图像。这是我们将在下一部分要做的。</p><p><br></p><h2><b>扩展阅读</b></h2><ol><li><a href="https://link.zhihu.com/?target=http%3A//pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">PyTorch tutorial</a></li><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DDNEm4fJ-rto" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">IoU</a></li><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DA46HZGR5fMw" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Non maximum suppresion</a></li><li><a href="https://link.zhihu.com/?target=https%3A//www.google.co.in/search%3Fq%3DNMS%2Bpython%26oq%3DNMS%2Bpython%2B%26aqs%3Dchrome..69i57j35i39.2657j0j7%26sourceid%3Dchrome%26ie%3DUTF-8" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Non-maximum Suppression</a></li></ol></div></div><div class="ContentItem-time"><a target="_blank" href="http://zhuanlan.zhihu.com/p/36998818"><span data-tooltip="发布于 2018-05-24 01:50">编辑于 2018-05-24</span></a></div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19813032&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19813032" target="_blank"><div class="Popover"><div id="Popover-96276-61123-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96276-61123-content">深度学习（Deep Learning）</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19596960&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19596960" target="_blank"><div class="Popover"><div id="Popover-96277-83556-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96277-83556-content">目标检测</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;20075993&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/20075993" target="_blank"><div class="Popover"><div id="Popover-96277-15982-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96277-15982-content">PyTorch</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 690px; bottom: 0px; left: 414.6px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;36998818&quot;}}}"><button type="button" class="Button LikeButton ContentItem-action"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--like" style="height:16px;width:13px" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.718 7.024c-.718 0-.718.63-.718.63l.996 9.693c0 .703.718.65.718.65h1.45c.916 0 .847-.65.847-.65V7.793c-.09-.88-.853-.79-.846-.79l-2.446.02zm11.727-.05S13.2 5.396 13.6 2.89C13.765.03 11.55-.6 10.565.53c-1.014 1.232 0 2.056-4.45 5.83C5.336 6.965 5 8.01 5 8.997v6.998c-.016 1.104.49 2 1.99 2h7.586c2.097 0 2.86-1.416 2.86-1.416s2.178-5.402 2.346-5.91c1.047-3.516-1.95-3.704-1.95-3.704l-5.387.007z"></path></g></svg>2</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>添加评论</button><div class="Popover ShareMenu ContentItem-action"><div class="" id="Popover-96277-89968-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96277-89968-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover-96277-49546-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-96277-49546-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div data-za-detail-view-path-module="LeftTabBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;36998818&quot;}}}"><div><div class="Post-SideActions" style="opacity: 1;"><button class="like"><div class="Post-SideActions-icon"><svg class="Zi Zi--Like" height="48" fill="currentColor" viewBox="0 0 24 24" width="24"><path d="M2.718 10.024c-.718 0-.718.63-.718.63l.996 9.693c0 .703.718.649.718.649h1.45c.916 0 .847-.649.847-.649v-9.554c-.09-.879-.854-.791-.847-.791l-2.446.022zm11.727-.05s.756-1.577 1.156-4.083c.163-2.861-2.052-3.491-3.037-2.362-1.014 1.233 0 2.057-4.45 5.83C7.336 9.966 7 11.011 7 11.998v6.998c-.016 1.104.491 2 1.99 2h7.586c2.097 0 2.86-1.416 2.86-1.416s2.178-5.402 2.346-5.911c1.047-3.515-1.95-3.703-1.95-3.703l-5.387.007z" fill-rule="evenodd"></path></svg></div><div class="likeCount"><div class="likeCount-inner" data-previous="3">2</div></div></button><div class="Popover ShareMenu"><div class="" id="Popover-14699-97812-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-14699-97812-content"><button><div class="Post-SideActions-icon"><svg class="Zi Zi--Share" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></div>分享</button></div></div></div></div></div></div><div class="Sticky--holder" style="position: static; top: auto; right: auto; bottom: 0px; left: 0px; display: block; float: none; margin: 0px 0px 10px; height: 54px;"></div></div><div class="Recommendations-Main" style="width: 1519px;"><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class="Recommendations-List"><button class="PagingButton PagingButton-Previous" disabled=""><svg class="Zi Zi--ArrowLeft" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M14.782 16.78a.737.737 0 0 1-1.052 0L9.218 12.53a.758.758 0 0 1 0-1.063L13.73 7.22a.737.737 0 0 1 1.052 0c.29.294.29.77.001 1.063L11 12l3.782 3.716c.29.294.29.77 0 1.063z" fill-rule="evenodd"></path></svg></button><a href="http://zhuanlan.zhihu.com/p/36902889" class="PostItem"><div><img src="./从零开始实现YOLO v3（part4）_files/v2-4f8c038e58e8048c8432c330b1c4195f_250x0.jpg" srcset="https://pic2.zhimg.com/v2-4f8c038e58e8048c8432c330b1c4195f_qhd.jpg 2x" class="PostItem-TitleImage" alt="Tensorflow实现YOLO2"><h1 class="PostItem-Title">Tensorflow实现YOLO2</h1><div class="PostItem-Footer"><span>KOD Chen</span><span class="PostItem-FooterTitle"></span></div></div></a><a href="http://zhuanlan.zhihu.com/p/36020561" class="PostItem"><div><img src="./从零开始实现YOLO v3（part4）_files/v2-973336f8e20791e19f83d11280381cfa_250x0.jpg" srcset="https://pic3.zhimg.com/v2-973336f8e20791e19f83d11280381cfa_qhd.jpg 2x" class="PostItem-TitleImage" alt="从零开始PyTorch项目：YOLO v3目标检测实现（上）"><h1 class="PostItem-Title">从零开始PyTorch项目：YOLO v3目标检测实现（上）</h1><div class="PostItem-Footer"><span>机器之心</span><span class="PostItem-FooterTitle"></span></div></div></a><a href="http://zhuanlan.zhihu.com/p/36220256" class="PostItem"><div><img src="./从零开始实现YOLO v3（part4）_files/v2-8bb0c3f448aca51dc0a42ef1c0ce97a4_250x0.jpg" srcset="https://pic2.zhimg.com/v2-8bb0c3f448aca51dc0a42ef1c0ce97a4_qhd.jpg 2x" class="PostItem-TitleImage" alt="从零开始PyTorch项目：YOLO v3目标检测实现（下）"><h1 class="PostItem-Title">从零开始PyTorch项目：YOLO v3目标检测实现（下）</h1><div class="PostItem-Footer"><span>机器之心</span><span class="PostItem-FooterTitle">发表于机器之心</span></div></div></a><a href="http://zhuanlan.zhihu.com/p/32945351" class="PostItem"><div><img src="./从零开始实现YOLO v3（part4）_files/v2-1afee0469531cf27b3e0e7bfd439a10c_250x0.jpg" srcset="https://pic1.zhimg.com/v2-1afee0469531cf27b3e0e7bfd439a10c_qhd.jpg 2x" class="PostItem-TitleImage" alt="YOLO，一种简易快捷的目标检测算法"><h1 class="PostItem-Title">YOLO，一种简易快捷的目标检测算法</h1><div class="PostItem-Footer"><span>兔子老大</span><span class="PostItem-FooterTitle"></span></div></div></a><button class="PagingButton PagingButton-Next"><svg class="Zi Zi--ArrowRight" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M9.218 16.78a.737.737 0 0 0 1.052 0l4.512-4.249a.758.758 0 0 0 0-1.063L10.27 7.22a.737.737 0 0 0-1.052 0 .759.759 0 0 0-.001 1.063L13 12l-3.782 3.716a.758.758 0 0 0 0 1.063z" fill-rule="evenodd"></path></svg></button></ul></div><div class="Comments-container" data-za-detail-view-path-module="CommentList" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:null}}"><div class="Comments Comments--withEditor Comments-withPagination"><div class="Topbar CommentTopbar"><div class="Topbar-title"><h2 class="CommentTopbar-title">还没有评论</h2></div><div class="Topbar-options"></div></div><div class="Comments-footer CommentEditor--normal"><div class="CommentEditor-input Input-wrapper Input-wrapper--spread Input-wrapper--large Input-wrapper--noPadding"><div class="Input Editable"><div class="Dropzone RichText ztext" style="min-height: 198px;"><div class="DraftEditor-root"><div class="public-DraftEditorPlaceholder-root"><div class="public-DraftEditorPlaceholder-inner" id="placeholder-ef6em">写下你的评论...</div></div><div class="DraftEditor-editorContainer"><div aria-describedby="placeholder-ef6em" class="notranslate public-DraftEditor-content" contenteditable="true" role="textbox" spellcheck="true" tabindex="0" style="outline: none; white-space: pre-wrap; word-wrap: break-word;"><div data-contents="true"><div class="Editable-unstyled" data-block="true" data-editor="ef6em" data-offset-key="qlg1-0-0"><div data-offset-key="qlg1-0-0" class="public-DraftStyleDefault-block public-DraftStyleDefault-ltr"><span data-offset-key="qlg1-0-0"><br data-text="true"></span></div></div></div></div></div></div></div><input multiple="" type="file" accept="image/jpg,image/jpeg,image/png,image/gif" style="display: none;"><div></div></div></div><button disabled="" type="button" class="Button CommentEditor-singleButton Button--primary Button--blue">评论</button></div><div><div class="CommentList"></div><span></span></div></div></div></article></div></main><div class="CornerButtons"><div class="CornerAnimayedFlex"><button data-tooltip="回到顶部" data-tooltip-position="left" aria-label="回到顶部" type="button" class="Button CornerButton Button--plain"><svg class="Zi Zi--BackToTop" title="回到顶部" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M16.036 19.59a1 1 0 0 1-.997.995H9.032a.996.996 0 0 1-.997-.996v-7.005H5.03c-1.1 0-1.36-.633-.578-1.416L11.33 4.29a1.003 1.003 0 0 1 1.412 0l6.878 6.88c.782.78.523 1.415-.58 1.415h-3.004v7.005z"></path></svg></button></div></div></div></div><div id="data" style="display:none" data-useragent="{&quot;os&quot;:{&quot;name&quot;:&quot;Windows&quot;,&quot;version&quot;:&quot;10&quot;},&quot;browser&quot;:{&quot;name&quot;:&quot;Chrome&quot;,&quot;version&quot;:&quot;67.0.3396.62&quot;,&quot;major&quot;:&quot;67&quot;}}"></div><script src="./从零开始实现YOLO v3（part4）_files/vendor.c1ed8d16a6988c3797dd.js.下载"></script><script src="./从零开始实现YOLO v3（part4）_files/column.raven.3e44c47f950b171e427a.js.下载" defer=""></script><script src="./从零开始实现YOLO v3（part4）_files/column.app.d4747a7c63fc53f41c4e.js.下载"></script><script></script><div><div style="display: none;">想来知乎工作？请发送邮件到 jobs@zhihu.com</div></div><div><div><div class="Editable-languageSuggestions" style="left: -1179px; top: -999px;"><div><div class="Popover"><div class="Editable-languageSuggestionsInput Input-wrapper"><input autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplet-96459-67902-0" id="Popover-96459-56198-toggle" aria-haspopup="true" aria-owns="Popover-96459-56198-content" class="Input" placeholder="选择语言" value=""><div class="Input-after"><svg class="Zi Zi--Select" fill="#afbdcf" viewBox="0 0 24 24" width="24" height="24"><path d="M12 16.183l2.716-2.966a.757.757 0 0 1 1.064.001.738.738 0 0 1 0 1.052l-3.247 3.512a.758.758 0 0 1-1.064 0L8.22 14.27a.738.738 0 0 1 0-1.052.758.758 0 0 1 1.063 0L12 16.183zm0-9.365L9.284 9.782a.758.758 0 0 1-1.064 0 .738.738 0 0 1 0-1.052l3.248-3.512a.758.758 0 0 1 1.065 0L15.78 8.73a.738.738 0 0 1 0 1.052.757.757 0 0 1-1.063.001L12 6.818z" fill-rule="evenodd"></path></svg></div></div></div></div></div></div></div></body></html>